22/07/22 16:07:23 WARN spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
22/07/22 16:07:23 WARN spark.SparkConf: The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead.
22/07/22 16:07:23 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
22/07/22 16:07:23 WARN spark.SparkConf: The configuration key 'spark.yarn.executor.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.executor.memoryOverhead' instead.
22/07/22 16:07:23 WARN spark.SparkConf: The configuration key 'spark.yarn.driver.memoryOverhead' has been deprecated as of Spark 2.3 and may be removed in the future. Please use the new key 'spark.driver.memoryOverhead' instead.
22/07/22 16:07:23 INFO spark.SparkContext: Running Spark version 2.4.6
22/07/22 16:07:23 INFO spark.SparkContext: Submitted application: ScalaPageRank
22/07/22 16:07:23 INFO spark.SecurityManager: Changing view acls to: root
22/07/22 16:07:23 INFO spark.SecurityManager: Changing modify acls to: root
22/07/22 16:07:23 INFO spark.SecurityManager: Changing view acls groups to: 
22/07/22 16:07:23 INFO spark.SecurityManager: Changing modify acls groups to: 
22/07/22 16:07:23 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
22/07/22 16:07:23 INFO util.Utils: Successfully started service 'sparkDriver' on port 44567.
22/07/22 16:07:23 INFO spark.SparkEnv: Registering MapOutputTracker
22/07/22 16:07:23 INFO spark.SparkEnv: Registering BlockManagerMaster
22/07/22 16:07:23 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/07/22 16:07:23 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/07/22 16:07:23 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-13427dd1-1738-4164-8e48-3749bb3c1695
22/07/22 16:07:24 INFO memory.MemoryStore: MemoryStore started with capacity 1007.8 MB
22/07/22 16:07:24 INFO spark.SparkEnv: Registering OutputCommitCoordinator
22/07/22 16:07:24 INFO util.log: Logging initialized @1740ms
22/07/22 16:07:24 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
22/07/22 16:07:24 INFO server.Server: Started @1795ms
22/07/22 16:07:24 INFO server.AbstractConnector: Started ServerConnector@3e792ce3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
22/07/22 16:07:24 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4201a617{/jobs,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5aa360ea{/jobs/json,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6548bb7d{/jobs/job,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@54336c81{/jobs/job/json,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1556f2dd{/stages,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@35e52059{/stages/json,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@62577d6{/stages/stage,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@772485dd{/stages/stage/json,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5a12c728{/stages/pool,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@79ab3a71{/stages/pool/json,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6e5bfdfc{/storage,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3d829787{/storage/json,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@71652c98{/storage/rdd,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@51bde877{/storage/rdd/json,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@60b85ba1{/environment,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@492fc69e{/environment/json,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@117632cf{/executors,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2fb68ec6{/executors/json,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@d71adc2{/executors/threadDump,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3add81c4{/executors/threadDump/json,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1a1d3c1a{/static,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6d2260db{/,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1f2d2181{/api,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7668d560{/jobs/job/kill,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@46292372{/stages/stage/kill,null,AVAILABLE,@Spark}
22/07/22 16:07:24 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://spark-hadoop-hibench-master-1-0.spark-hadoop-hibench-master-1.default.svc.cluster.local:4040
22/07/22 16:07:24 INFO spark.SparkContext: Added JAR file:/root/spark-hadoop/HiBench-HiBench-7.1/sparkbench/assembly/target/sparkbench-assembly-7.1-dist.jar at spark://spark-hadoop-hibench-master-1-0.spark-hadoop-hibench-master-1.default.svc.cluster.local:44567/jars/sparkbench-assembly-7.1-dist.jar with timestamp 1658477244229
22/07/22 16:07:24 INFO client.RMProxy: Connecting to ResourceManager at spark-hadoop-hibench-master-1.default.svc.cluster.local/10.244.1.204:8032
22/07/22 16:07:25 INFO yarn.Client: Requesting a new application from cluster with 4 NodeManagers
22/07/22 16:07:25 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (8192 MB per container)
22/07/22 16:07:25 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead
22/07/22 16:07:25 INFO yarn.Client: Setting up container launch context for our AM
22/07/22 16:07:25 INFO yarn.Client: Setting up the launch environment for our AM container
22/07/22 16:07:25 INFO yarn.Client: Preparing resources for our AM container
22/07/22 16:07:25 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
22/07/22 16:07:26 INFO yarn.Client: Uploading resource file:/tmp/spark-b5bab11e-d8eb-4895-9b9a-f07fbb91a451/__spark_libs__1829635181612967707.zip -> hdfs://10.0.0.61:9005/user/root/.sparkStaging/application_1658476048180_0002/__spark_libs__1829635181612967707.zip
22/07/22 16:07:27 INFO yarn.Client: Uploading resource file:/tmp/spark-b5bab11e-d8eb-4895-9b9a-f07fbb91a451/__spark_conf__6571100538712375093.zip -> hdfs://10.0.0.61:9005/user/root/.sparkStaging/application_1658476048180_0002/__spark_conf__.zip
22/07/22 16:07:27 INFO spark.SecurityManager: Changing view acls to: root
22/07/22 16:07:27 INFO spark.SecurityManager: Changing modify acls to: root
22/07/22 16:07:27 INFO spark.SecurityManager: Changing view acls groups to: 
22/07/22 16:07:27 INFO spark.SecurityManager: Changing modify acls groups to: 
22/07/22 16:07:27 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
22/07/22 16:07:27 INFO yarn.Client: Submitting application application_1658476048180_0002 to ResourceManager
22/07/22 16:07:27 INFO impl.YarnClientImpl: Submitted application application_1658476048180_0002
22/07/22 16:07:27 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1658476048180_0002 and attemptId None
22/07/22 16:07:28 INFO yarn.Client: Application report for application_1658476048180_0002 (state: ACCEPTED)
22/07/22 16:07:28 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: N/A
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1658477247940
	 final status: UNDEFINED
	 tracking URL: http://spark-hadoop-hibench-master-1.default.svc.cluster.local:8088/proxy/application_1658476048180_0002/
	 user: root
22/07/22 16:07:29 INFO yarn.Client: Application report for application_1658476048180_0002 (state: ACCEPTED)
22/07/22 16:07:30 INFO yarn.Client: Application report for application_1658476048180_0002 (state: ACCEPTED)
22/07/22 16:07:31 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> spark-hadoop-hibench-master-1.default.svc.cluster.local, PROXY_URI_BASES -> http://spark-hadoop-hibench-master-1.default.svc.cluster.local:8088/proxy/application_1658476048180_0002), /proxy/application_1658476048180_0002
22/07/22 16:07:31 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)
22/07/22 16:07:31 INFO yarn.Client: Application report for application_1658476048180_0002 (state: RUNNING)
22/07/22 16:07:31 INFO yarn.Client: 
	 client token: N/A
	 diagnostics: N/A
	 ApplicationMaster host: 10.244.1.209
	 ApplicationMaster RPC port: -1
	 queue: default
	 start time: 1658477247940
	 final status: UNDEFINED
	 tracking URL: http://spark-hadoop-hibench-master-1.default.svc.cluster.local:8088/proxy/application_1658476048180_0002/
	 user: root
22/07/22 16:07:31 INFO cluster.YarnClientSchedulerBackend: Application application_1658476048180_0002 has started running.
22/07/22 16:07:32 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38529.
22/07/22 16:07:32 INFO netty.NettyBlockTransferService: Server created on spark-hadoop-hibench-master-1-0.spark-hadoop-hibench-master-1.default.svc.cluster.local:38529
22/07/22 16:07:32 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/07/22 16:07:32 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, spark-hadoop-hibench-master-1-0.spark-hadoop-hibench-master-1.default.svc.cluster.local, 38529, None)
22/07/22 16:07:32 INFO storage.BlockManagerMasterEndpoint: Registering block manager spark-hadoop-hibench-master-1-0.spark-hadoop-hibench-master-1.default.svc.cluster.local:38529 with 1007.8 MB RAM, BlockManagerId(driver, spark-hadoop-hibench-master-1-0.spark-hadoop-hibench-master-1.default.svc.cluster.local, 38529, None)
22/07/22 16:07:32 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, spark-hadoop-hibench-master-1-0.spark-hadoop-hibench-master-1.default.svc.cluster.local, 38529, None)
22/07/22 16:07:32 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, spark-hadoop-hibench-master-1-0.spark-hadoop-hibench-master-1.default.svc.cluster.local, 38529, None)
22/07/22 16:07:32 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.
22/07/22 16:07:32 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@8b13d91{/metrics/json,null,AVAILABLE,@Spark}
22/07/22 16:07:34 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.244.1.209:39728) with ID 2
22/07/22 16:07:34 INFO storage.BlockManagerMasterEndpoint: Registering block manager spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local:44489 with 1007.8 MB RAM, BlockManagerId(2, spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local, 44489, None)
22/07/22 16:07:35 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.244.1.217:40530) with ID 4
22/07/22 16:07:35 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.244.1.213:60744) with ID 3
22/07/22 16:07:35 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.244.1.205:60346) with ID 1
22/07/22 16:07:35 INFO storage.BlockManagerMasterEndpoint: Registering block manager spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local:34363 with 1007.8 MB RAM, BlockManagerId(4, spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local, 34363, None)
22/07/22 16:07:35 INFO storage.BlockManagerMasterEndpoint: Registering block manager spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local:33215 with 1007.8 MB RAM, BlockManagerId(3, spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local, 33215, None)
22/07/22 16:07:35 INFO storage.BlockManagerMasterEndpoint: Registering block manager spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local:35895 with 1007.8 MB RAM, BlockManagerId(1, spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local, 35895, None)
22/07/22 16:07:35 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.8
22/07/22 16:07:35 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 241.7 KB, free 1007.6 MB)
22/07/22 16:07:35 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.3 KB, free 1007.6 MB)
22/07/22 16:07:35 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on spark-hadoop-hibench-master-1-0.spark-hadoop-hibench-master-1.default.svc.cluster.local:38529 (size: 23.3 KB, free: 1007.8 MB)
22/07/22 16:07:35 INFO spark.SparkContext: Created broadcast 0 from textFile at SparkPageRank.scala:53
22/07/22 16:07:35 INFO mapred.FileInputFormat: Total input paths to process : 16
22/07/22 16:07:35 INFO net.NetworkTopology: Adding a new node: /default-rack/10.0.0.63:50010
22/07/22 16:07:35 INFO net.NetworkTopology: Adding a new node: /default-rack/10.0.0.64:50010
22/07/22 16:07:35 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
22/07/22 16:07:35 INFO io.HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
22/07/22 16:07:35 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
22/07/22 16:07:35 INFO spark.SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
22/07/22 16:07:36 INFO scheduler.DAGScheduler: Registering RDD 3 (distinct at SparkPageRank.scala:58) as input to shuffle 2
22/07/22 16:07:36 INFO scheduler.DAGScheduler: Registering RDD 5 (distinct at SparkPageRank.scala:58) as input to shuffle 1
22/07/22 16:07:36 INFO scheduler.DAGScheduler: Registering RDD 12 (flatMap at SparkPageRank.scala:62) as input to shuffle 0
22/07/22 16:07:36 INFO scheduler.DAGScheduler: Got job 0 (runJob at SparkHadoopWriter.scala:78) with 8 output partitions
22/07/22 16:07:36 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (runJob at SparkHadoopWriter.scala:78)
22/07/22 16:07:36 INFO scheduler.DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
22/07/22 16:07:36 INFO scheduler.DAGScheduler: Missing parents: List(ShuffleMapStage 2)
22/07/22 16:07:36 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at SparkPageRank.scala:58), which has no missing parents
22/07/22 16:07:36 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.7 KB, free 1007.6 MB)
22/07/22 16:07:36 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1007.6 MB)
22/07/22 16:07:36 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-hadoop-hibench-master-1-0.spark-hadoop-hibench-master-1.default.svc.cluster.local:38529 (size: 2.7 KB, free: 1007.8 MB)
22/07/22 16:07:36 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1163
22/07/22 16:07:36 INFO scheduler.DAGScheduler: Submitting 16 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at distinct at SparkPageRank.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
22/07/22 16:07:36 INFO cluster.YarnScheduler: Adding task set 0.0 with 16 tasks
22/07/22 16:07:36 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 1, partition 0, RACK_LOCAL, 7922 bytes)
22/07/22 16:07:36 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 4, partition 1, RACK_LOCAL, 7922 bytes)
22/07/22 16:07:36 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 2, partition 2, RACK_LOCAL, 7922 bytes)
22/07/22 16:07:36 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 3, partition 3, RACK_LOCAL, 7922 bytes)
22/07/22 16:07:36 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 1, partition 4, RACK_LOCAL, 7922 bytes)
22/07/22 16:07:36 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 4, partition 5, RACK_LOCAL, 7922 bytes)
22/07/22 16:07:36 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 2, partition 6, RACK_LOCAL, 7922 bytes)
22/07/22 16:07:36 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 3, partition 7, RACK_LOCAL, 7922 bytes)
22/07/22 16:07:36 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local:33215 (size: 2.7 KB, free: 1007.8 MB)
22/07/22 16:07:36 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local:34363 (size: 2.7 KB, free: 1007.8 MB)
22/07/22 16:07:36 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local:33215 (size: 23.3 KB, free: 1007.8 MB)
22/07/22 16:07:36 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local:35895 (size: 2.7 KB, free: 1007.8 MB)
22/07/22 16:07:36 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local:44489 (size: 2.7 KB, free: 1007.8 MB)
22/07/22 16:07:37 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local:34363 (size: 23.3 KB, free: 1007.8 MB)
22/07/22 16:07:37 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local:35895 (size: 23.3 KB, free: 1007.8 MB)
22/07/22 16:07:37 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local:44489 (size: 23.3 KB, free: 1007.8 MB)
22/07/22 16:09:13 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 1, partition 8, RACK_LOCAL, 7922 bytes)
22/07/22 16:09:13 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 97641 ms on spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 1) (1/16)
22/07/22 16:09:15 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 1, partition 9, RACK_LOCAL, 7922 bytes)
22/07/22 16:09:15 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 98779 ms on spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 1) (2/16)
22/07/22 16:09:15 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 0.0 (TID 10, spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 4, partition 10, RACK_LOCAL, 7922 bytes)
22/07/22 16:09:15 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 99565 ms on spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 4) (3/16)
22/07/22 16:09:20 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 0.0 (TID 11, spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 4, partition 11, RACK_LOCAL, 7922 bytes)
22/07/22 16:09:20 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 103945 ms on spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 4) (4/16)
22/07/22 16:09:26 INFO scheduler.TaskSetManager: Starting task 12.0 in stage 0.0 (TID 12, spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 2, partition 12, RACK_LOCAL, 7922 bytes)
22/07/22 16:09:26 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 110311 ms on spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 2) (5/16)
22/07/22 16:09:28 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 0.0 (TID 13, spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 2, partition 13, RACK_LOCAL, 7922 bytes)
22/07/22 16:09:28 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 112672 ms on spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 2) (6/16)
22/07/22 16:09:38 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 0.0 (TID 14, spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 3, partition 14, RACK_LOCAL, 7922 bytes)
22/07/22 16:09:38 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 121759 ms on spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 3) (7/16)
22/07/22 16:09:43 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 0.0 (TID 15, spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 3, partition 15, RACK_LOCAL, 7922 bytes)
22/07/22 16:09:43 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 127677 ms on spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 3) (8/16)
22/07/22 16:11:10 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 116376 ms on spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 1) (9/16)
22/07/22 16:11:16 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 121360 ms on spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 1) (10/16)
22/07/22 16:11:20 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 0.0 (TID 10) in 124566 ms on spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 4) (11/16)
22/07/22 16:11:22 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 0.0 (TID 11) in 122170 ms on spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 4) (12/16)
22/07/22 16:11:33 INFO scheduler.TaskSetManager: Finished task 12.0 in stage 0.0 (TID 12) in 126715 ms on spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 2) (13/16)
22/07/22 16:11:41 INFO scheduler.TaskSetManager: Finished task 13.0 in stage 0.0 (TID 13) in 132887 ms on spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 2) (14/16)
22/07/22 16:11:46 INFO scheduler.TaskSetManager: Finished task 14.0 in stage 0.0 (TID 14) in 128270 ms on spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 3) (15/16)
22/07/22 16:11:50 INFO scheduler.TaskSetManager: Finished task 15.0 in stage 0.0 (TID 15) in 126278 ms on spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 3) (16/16)
22/07/22 16:11:50 INFO scheduler.DAGScheduler: ShuffleMapStage 0 (distinct at SparkPageRank.scala:58) finished in 254.136 s
22/07/22 16:11:50 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool 
22/07/22 16:11:50 INFO scheduler.DAGScheduler: looking for newly runnable stages
22/07/22 16:11:50 INFO scheduler.DAGScheduler: running: Set()
22/07/22 16:11:50 INFO scheduler.DAGScheduler: waiting: Set(ShuffleMapStage 1, ShuffleMapStage 2, ResultStage 3)
22/07/22 16:11:50 INFO scheduler.DAGScheduler: failed: Set()
22/07/22 16:11:50 INFO scheduler.DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at distinct at SparkPageRank.scala:58), which has no missing parents
22/07/22 16:11:50 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.9 KB, free 1007.6 MB)
22/07/22 16:11:50 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1007.6 MB)
22/07/22 16:11:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on spark-hadoop-hibench-master-1-0.spark-hadoop-hibench-master-1.default.svc.cluster.local:38529 (size: 2.7 KB, free: 1007.8 MB)
22/07/22 16:11:50 INFO spark.SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1163
22/07/22 16:11:50 INFO scheduler.DAGScheduler: Submitting 16 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at distinct at SparkPageRank.scala:58) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))
22/07/22 16:11:50 INFO cluster.YarnScheduler: Adding task set 1.0 with 16 tasks
22/07/22 16:11:50 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 16, spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 2, partition 0, NODE_LOCAL, 7662 bytes)
22/07/22 16:11:50 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 1.0 (TID 17, spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 4, partition 1, NODE_LOCAL, 7662 bytes)
22/07/22 16:11:50 INFO scheduler.TaskSetManager: Starting task 2.0 in stage 1.0 (TID 18, spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 3, partition 2, NODE_LOCAL, 7662 bytes)
22/07/22 16:11:50 INFO scheduler.TaskSetManager: Starting task 3.0 in stage 1.0 (TID 19, spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 1, partition 3, NODE_LOCAL, 7662 bytes)
22/07/22 16:11:50 INFO scheduler.TaskSetManager: Starting task 4.0 in stage 1.0 (TID 20, spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 2, partition 4, NODE_LOCAL, 7662 bytes)
22/07/22 16:11:50 INFO scheduler.TaskSetManager: Starting task 5.0 in stage 1.0 (TID 21, spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 4, partition 5, NODE_LOCAL, 7662 bytes)
22/07/22 16:11:50 INFO scheduler.TaskSetManager: Starting task 6.0 in stage 1.0 (TID 22, spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 3, partition 6, NODE_LOCAL, 7662 bytes)
22/07/22 16:11:50 INFO scheduler.TaskSetManager: Starting task 7.0 in stage 1.0 (TID 23, spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 1, partition 7, NODE_LOCAL, 7662 bytes)
22/07/22 16:11:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local:33215 (size: 2.7 KB, free: 1007.8 MB)
22/07/22 16:11:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local:34363 (size: 2.7 KB, free: 1007.8 MB)
22/07/22 16:11:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local:35895 (size: 2.7 KB, free: 1007.8 MB)
22/07/22 16:11:50 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local:44489 (size: 2.7 KB, free: 1007.8 MB)
22/07/22 16:11:50 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.244.1.213:60744
22/07/22 16:11:50 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.244.1.205:60346
22/07/22 16:11:50 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.244.1.217:40530
22/07/22 16:11:50 INFO spark.MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to 10.244.1.209:39728
22/07/22 16:13:46 INFO scheduler.TaskSetManager: Starting task 8.0 in stage 1.0 (TID 24, spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 1, partition 8, NODE_LOCAL, 7662 bytes)
22/07/22 16:13:46 INFO scheduler.TaskSetManager: Finished task 3.0 in stage 1.0 (TID 19) in 116235 ms on spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 1) (1/16)
22/07/22 16:13:47 INFO scheduler.TaskSetManager: Starting task 9.0 in stage 1.0 (TID 25, spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 2, partition 9, NODE_LOCAL, 7662 bytes)
22/07/22 16:13:47 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 16) in 117592 ms on spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 2) (2/16)
22/07/22 16:13:47 INFO scheduler.TaskSetManager: Starting task 10.0 in stage 1.0 (TID 26, spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 1, partition 10, NODE_LOCAL, 7662 bytes)
22/07/22 16:13:47 INFO scheduler.TaskSetManager: Finished task 7.0 in stage 1.0 (TID 23) in 117606 ms on spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 1) (3/16)
22/07/22 16:13:50 INFO scheduler.TaskSetManager: Starting task 11.0 in stage 1.0 (TID 27, spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 2, partition 11, NODE_LOCAL, 7662 bytes)
22/07/22 16:13:50 INFO scheduler.TaskSetManager: Finished task 4.0 in stage 1.0 (TID 20) in 120683 ms on spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 2) (4/16)
22/07/22 16:13:56 INFO scheduler.TaskSetManager: Starting task 12.0 in stage 1.0 (TID 28, spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 4, partition 12, NODE_LOCAL, 7662 bytes)
22/07/22 16:13:56 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 1.0 (TID 17) in 126510 ms on spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 4) (5/16)
22/07/22 16:13:57 INFO scheduler.TaskSetManager: Starting task 13.0 in stage 1.0 (TID 29, spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 4, partition 13, NODE_LOCAL, 7662 bytes)
22/07/22 16:13:57 INFO scheduler.TaskSetManager: Finished task 5.0 in stage 1.0 (TID 21) in 127492 ms on spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 4) (6/16)
22/07/22 16:14:01 INFO scheduler.TaskSetManager: Starting task 14.0 in stage 1.0 (TID 30, spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 3, partition 14, NODE_LOCAL, 7662 bytes)
22/07/22 16:14:01 INFO scheduler.TaskSetManager: Finished task 6.0 in stage 1.0 (TID 22) in 131646 ms on spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 3) (7/16)
22/07/22 16:14:01 INFO scheduler.TaskSetManager: Starting task 15.0 in stage 1.0 (TID 31, spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local, executor 3, partition 15, NODE_LOCAL, 7662 bytes)
22/07/22 16:14:01 INFO scheduler.TaskSetManager: Finished task 2.0 in stage 1.0 (TID 18) in 131648 ms on spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 3) (8/16)
22/07/22 16:15:35 INFO scheduler.TaskSetManager: Finished task 9.0 in stage 1.0 (TID 25) in 107167 ms on spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 2) (9/16)
22/07/22 16:15:35 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Disabling executor 4.
22/07/22 16:15:35 INFO scheduler.DAGScheduler: Executor lost: 4 (epoch 1)
22/07/22 16:15:35 INFO storage.BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
22/07/22 16:15:35 INFO storage.BlockManagerMasterEndpoint: Removing block manager BlockManagerId(4, spark-hadoop-hibench-slave-1-3.spark-hadoop-hibench-slave-1.default.svc.cluster.local, 34363, None)
22/07/22 16:15:35 INFO storage.BlockManagerMaster: Removed 4 successfully in removeExecutor
22/07/22 16:15:35 INFO scheduler.DAGScheduler: Shuffle files lost for executor: 4 (epoch 1)
22/07/22 16:15:37 INFO scheduler.TaskSetManager: Finished task 11.0 in stage 1.0 (TID 27) in 106072 ms on spark-hadoop-hibench-slave-1-1.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 2) (10/16)
22/07/22 16:15:39 INFO scheduler.TaskSetManager: Finished task 10.0 in stage 1.0 (TID 26) in 111884 ms on spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 1) (11/16)
22/07/22 16:15:41 INFO scheduler.TaskSetManager: Finished task 8.0 in stage 1.0 (TID 24) in 115504 ms on spark-hadoop-hibench-slave-1-0.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 1) (12/16)
22/07/22 16:15:52 INFO scheduler.TaskSetManager: Finished task 14.0 in stage 1.0 (TID 30) in 110323 ms on spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 3) (13/16)
22/07/22 16:15:52 INFO scheduler.TaskSetManager: Finished task 15.0 in stage 1.0 (TID 31) in 110562 ms on spark-hadoop-hibench-slave-1-2.spark-hadoop-hibench-slave-1.default.svc.cluster.local (executor 3) (14/16)
